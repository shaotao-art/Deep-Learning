{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disc(nn.Module):\n",
    "    \"\"\"\n",
    "    input: (N, 6, 256, 256) x, y concat\n",
    "    output: (N, 1, 30, 30)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_channel) -> None:\n",
    "        super(Disc, self).__init__()\n",
    "        # conv block's: inchannel, outchannel, kernel_size, stride, padding\n",
    "                            # (6, 256, 256) \n",
    "        self.config_lst = [[img_channel*2, 64, 4, 2, 1],\n",
    "                            # (64, 128, 128)\n",
    "                            [64, 128, 4, 2, 1],\n",
    "                            # (128, 64, 64)\n",
    "                            [128, 256, 4, 2, 1],\n",
    "                            # (256, 32, 32)\n",
    "                            [256, 512, 4, 1, 1],\n",
    "                            # (512, 31, 31)\n",
    "                            [512, 1, 4, 1, 1]]\n",
    "                            # (1, 30, 30)\n",
    "        self.conv_layers = self._create_conv_layers()\n",
    "        # print(self.conv_layers)\n",
    "        \n",
    "    def _create_conv_layers(self):\n",
    "        layers_lst = []\n",
    "        for i in range(len(self.config_lst)):\n",
    "            layers_lst.append(self._conv_block(self.config_lst[i][0],\n",
    "                                                self.config_lst[i][1],\n",
    "                                                self.config_lst[i][2],\n",
    "                                                self.config_lst[i][3],\n",
    "                                                self.config_lst[i][4]))\n",
    "        return nn.Sequential(*layers_lst)\n",
    "\n",
    "\n",
    "    def _conv_block(self, inchannel, outchannel, k_s, s, p):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, k_s, s, p),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "\n",
    "\n",
    "\n",
    "class Gen(nn.Module):\n",
    "    def __init__(self, img_channel) -> None:\n",
    "        super(Gen, self).__init__()\n",
    "        # up and down block's: inchannel, outchannel, kernel_size, stride, padding\n",
    "        # in down block: the first two elements is inchannel, outchannel\n",
    "        # in up block: the first two elements is outchannel, inchannel\n",
    "        self.config_up_down = [[img_channel, 9, 7, 1, 3],\n",
    "                            [9, 18, 4, 2, 1],\n",
    "                            [18, 36, 4, 2, 1]]\n",
    "        # residual block's: inchannel, outchannel, kernel_size, stride, padding, repeat_time\n",
    "        self.config_residual = [36, 36, 3, 1, 1, 6]\n",
    "        self.down_block = self._down_block()\n",
    "        # print(self.down_block)\n",
    "        self.up_block = self._up_block()\n",
    "        # print(self.up_block)\n",
    "\n",
    "\n",
    "    def _residual_block(self, x, inchannel, outchannel, k_s, s, p):\n",
    "        layer = self._conv_block(inchannel, outchannel, k_s, s, p)\n",
    "        return x + layer(x)\n",
    "\n",
    "    def _conv_block(self, inchannel, outchannel, k_s, s, p):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, k_s, s, p),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "\n",
    "    def _down_block(self):\n",
    "        down_layers = []\n",
    "        for i in range(len(self.config_up_down)):\n",
    "            down_layers.append(self._conv_block(self.config_up_down[i][0], \n",
    "                                                self.config_up_down[i][1], \n",
    "                                                self.config_up_down[i][2],\n",
    "                                                self.config_up_down[i][3],\n",
    "                                                self.config_up_down[i][4]))\n",
    "        \n",
    "        return nn.Sequential(*down_layers)\n",
    "\n",
    "    def _deconv_block(self, inchannel, outchannel, k_s, s, p):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(inchannel, outchannel, k_s, s, p),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _up_block(self):\n",
    "        up_layers = []\n",
    "        for i in range(len(self.config_up_down) - 1, -1, -1):\n",
    "            up_layers.append(self._deconv_block(self.config_up_down[i][1], \n",
    "                                                self.config_up_down[i][0], \n",
    "                                                self.config_up_down[i][2],\n",
    "                                                self.config_up_down[i][3],\n",
    "                                                self.config_up_down[i][4]))\n",
    "        return nn.Sequential(*up_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.down_block:\n",
    "            x = layer(x)\n",
    "            # print(x.shape)\n",
    "        for _ in range(self.config_residual[-1]):\n",
    "            x = self._residual_block(x, \n",
    "                                self.config_residual[0],\n",
    "                                self.config_residual[1],\n",
    "                                self.config_residual[2],\n",
    "                                self.config_residual[3],\n",
    "                                self.config_residual[4])\n",
    "            # print(x.shape)\n",
    "        for layer in self.up_block:\n",
    "            x = layer(x)\n",
    "            # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 3, 256, 256)\n",
    "gen = Gen(3)\n",
    "gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3af478167759ae4c710e12d24127bdfea349371295ae8f284cff01b249577fd9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('snake': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}